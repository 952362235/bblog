在经典的程序设计中，人们输入的是规则和需要根据这些规则进行处理的数据，系统输出的是答案。
利用机器学习，人们输入的是数据和从这些数据中预期得到的答案，系统输出的是规则。这些规则随后可应用于新的数据，并使计算机自主生成答案。
机器学习系统是训练出来的，而不是明确地用程序编写出了的。
机器学习的技术定义：在预先定义好的可能性空间中，利用反馈信号的指引来寻找输入数据的有用表示。
深度学习是机器学习的一个分支领域：他是表示从数据中学习的一种新方法，强调从连续的层中进行学习，这些层对应于越来越有意义的表示。
神经网络中每层对输入数据所作的具体操作保存在该层的权重中，其本质是一串数字。
损失函数也叫目标函数，损失函数的输入是网络预测值与真实目标值，然后计算一个距离值，衡量该网络在这个示例上的效果好坏。
深度学习的基本技巧是利用这个距离值作为反馈信号来对权重值进行微调，以降低当前示例对应的损失值。这种调节由优化器来完成，它实现了所谓的反向传播算法，这是深度学习的核心算法。
机器学习简史：
1.概率建模   朴素贝叶斯算法  logistic回归
2.早期神经网络 卷积神经网络和反向传播算法结合
3.核方法 一组分类方法 支持向量机SVM 目标是通过在属于两个不同类别的两个数据点之间找到良好的决策边界。
4.决策树，随机森林与梯度提升机
5.回到神经网络 深度卷积神经网络
6.深度学习 两个基本特征 1，通过渐进的逐层的方式形成越来越复杂的表示。 2.对中间这些渐进的表示共同进行学习，每一层的变化都需要同时考虑上下两层的需要。
神经网络的数据表示：例子使用的数据存储在多维Numpy数组中，也叫张量。一般来说当前所有的机器学习系统都使用张量作为基本数据结构。
张量是一个数据容器，矩阵是二维张量，张量是矩阵向任意维度的推广.(张量的维度通常叫做轴)
1.标量(0D张量) 仅含一个数字的张量叫标量scalar 可以用ndim属性来查看一个Numpy张量轴的个数，张量轴的个数也叫做阶rank
2.向量(1D张量)
3.矩阵(2D张量)
4.3D张量与更高维张量
张量是由三个关键属性来定义的1.轴的个数 ndim   2.形状 整数元祖，表示张量沿每个轴维度的大小(元素个数)。 3.数据类型dtype
数据批量： 深度学习中所有数据张量的第一个轴都是样本轴 不会同时处理这个数据集，而是将数据拆分成小批量。
向量数据：数据集   时间序列数据 3d 图像数据三个维度 4d张量  视频数据 5d张量
1.如果两个形状不同的张量相加，较小的张量会被广播，以匹配较大的张量的形状。
广播包含两步 1，向较小的张量添加轴(广播轴)，使其ndim与较大的张量相同。 2，将较小的张量沿着新轴重复，使其形状与较大的张量相同。
2.张量点积
3.张量变形 是指改变张量的行和列，以得到想要的形状。 特殊的张量变形是转置，对矩阵做转置是将行和列互换。
神经网络入门
神经网络的基本数据结构是层，层是一个数据处理模块，层的状态是层的权重。
不同的张量格式与不同的数据处理类型需要用到不同的层，简单数据保存做2d张量中用密集连接层=全连接层=密集层=Dense（Keras）
序列数据做3d张量中，用循环层=keras LSTM层。     图像数据做4D张量中，用二维卷积层 keras Conv2D
在Keras中，构建深度学习模型就是将相互兼容的多个层拼接做一起，以建立有用的数据变换流程。这里层兼容性具体指的是每一层只接受特定形状的输入张量，并返回特定形状的输出张量。
电影评论分类：二分类问题
1.IMDB数据集
2.将列表转换为张量 （1.填充列表，使其相同的长度，再将列表转换成形状为(samples, word_indices)的整数张量，网络第一次使用能处理这种整数张量的层（Embedding）
(2)对列表进行one-hot编码，将其转换成0 1组成的向量。然后用dense层，他能够处理浮点数向量数据。
3.构建网络   带有relu激活的Dense层堆叠，  对于二分类问题网络最后一层应该是只有一个单元并使用sigmoid激活的Dense，输出标量是0-1范围的标量，表示概率
对于二分类问题的sigmoid标量输出，你应该使用binary_crossentropy。 无论你的问题是什么，rmsprop优化器通常是足够好的选择
4。验证你的方法
5.新数据预测结果
6.进一步实验
多分类问题  新闻分类
1.路透社数据集
最后一层使用sofatmax激活，网络将输出做多个不同输出类别上的概率分布。概率总和为1·
对于这个例子最好的损失函数是categorical_crossentropy分类交叉熵，用于衡量两个概率之间的距离，这里的两个概率分布分别水网络输出概率分布和标签的真实分布。通过连个分布的距离最小化，训练网络课使输出结果尽可能接近真实标签。
如果要对N个类别的数据点进行分类，网络最后一层应该是大小为N的Dense层。
对于单标签，多分类问题，网络的最后一层应该使用softmax激活，这样可以输出做N个输出类别上的概率分布。
处理多分类问题的标签有两种方法。1.通过分类编码one-hot对标签编码，然后使用categorical_crossentropy作为损失函数 2.将标签编码为整数，然后使用spars_categorical_crossentropy损失函数。
回归问题 预测房价   预测一个连续值而不是离散的标签
网络的最后一层只有一个单元，没有激活，是一个线性层。这是标量回归(是预测单一连续值的回归)的典型设置。添加激活函数会限制输出范围。
MSE损失函数 均方误差 预测值与目标值之差的平方，这是回归问题常用个损失函数。  MAE平均绝对误差
利用K折交叉验证，这种方法可以将可用数据划分为K个分区（4，5）实例化K个相同的模型，将每个模型做K-1个分区上训练，并在剩下的一个分区进行评估。模型的验证分数等于K个验证分数的平均值。
如果输入数据的特征具有不同的取值范围，应该先进行预处理，对每个特征单独进行缩放。
机器学习的四个分支
1.监督学习 最常见的机器数学类型。给定一组样品(通常是人工标注)他可以学会将输入数据映射到已知目标【也叫标注】。
虽然监督学习主要包括分类和回归，但还有更多的奇特变体，主要包括如下几种。
序列生成  语法树预测  目标检测 图像分割
2.无监督学习  在没有目标的情况下寻找输入数据的有趣变换，其目的在乎数据的可视化，数据压缩，数据去燥或更好的理解数据中的相关性。
无监督学习是数据分析的必备技能，在解决监督学习问题之前，为了更好的了解数据集，通常是一个必要的步骤。降维和聚类是无监督学习方法。
3.自监督学习 没有人工标注的标签的监督学习。
4.强化学习 在强化学习中，智能体接受有关其环境的信息，并学会选择使某种奖励最大化的行为。主要做游戏中现在
评估机器学习模型
机器学习的目的是得到可以泛化的模型，即前所未见的数据上表现很好的模型，而过拟合则是核心难点。
1.简单的留出验证  留出一定比例的数据作为测试集
2.K折验证 
3.带有打乱数据的重复K折验证  可用数据少，尽可能精确 可以选择
评估模型注意事项 1.数据代表性 通常应该随机打乱数据
2.时间箭头  不要时间泄露
3.数据冗余
数据预处理 特征工程和特征学习
1.数据预处理
（1.向量化  神经网络的所有输入和目标都必须是浮点数张量。无论处理什么数据，都必须首先将其转换为张量，这一步叫数据向量化。
（2.值标准化  一般来说，将取值相对较大的数据或异质数据输入到神经网络中是不安全的。这么做可能导致较大的梯度更新，进而网络无法收敛。
为了让网络的学习变得容易，输入数据应该具有以下特征：取值较小，0-1。 同质性 所有特征的取值都应该做大致相同的范围内
（3.处理缺失值  一般来说对于神经网络，将缺失值设为0是安全的，只要0不是一个有意义的值。网络能够从数据中学到0意味着缺失数据，并会忽略这个值。
如果测试数据中可能有缺失值，而网络在没有缺失值的数据上训练的，那么网络不可能学会忽略缺失值。
2.特征工程 指将数据输入模型之前，利用你自己关于数据和机器学习算法的知识对数据进行硬编码的变换，以改善模型的效果。
多数情况下，一个机器学习模型无法从完全任意的数据中进行学习。呈现给模型的数据应该便于模型进行学习。
本质就是用更简单的方式表述问题，从而使问题变得更容易。它通常需要深入理解问题。
过拟合与欠拟合
机器学习的根本问题是优化和泛化之间的对立。优化是指调节模型以做训练数据上得到最佳性能。泛化是指训练好的模型做前所未见的数据上的性能好坏。
最优的解决方法是获取更多的训练数据。
降低过拟合的方法叫做正则化：1.减小网络大小  减小模型的大小，就是减少可学习参数的大小（由层数和每层单元个数决定）
2.添加权重正则化   奥卡姆剃刀原理 两种解释  最可能正确的是最简单的那个。 因此一种常见的降低过拟合的方法就是强制让模型权重只能取较小的值，从而限制模型的复杂度，这使得权重值的分布更加规则。这种方法叫权重正则化
3.添加dropout正则化  对某层使用dorpout就是做训练过程中随机将该层的一些输出特征舍弃（0）dropout比率是被设置为0的特征所占的比例，通常做0.2-0.5间。
卷积神经网络convner
1.卷积元素  密集连接层和卷积层的根本区别在于，dense层从输入特征空间中学到的是全局模式，卷积层学到的是局部模式，对于对象来说学到的就是做输入图像的二维小窗口中发现的模式。
这个重要的特性使卷积神经网络有两个有趣的性质
（1）卷积神经网络学到的模式具有平移不变性。（2）可以学到模式的空间层次结构
（1）理解边界效应与填充 （2）理解卷积步幅
2.最大池化运算
